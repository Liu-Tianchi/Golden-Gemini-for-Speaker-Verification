# Golden-Gemini-for-Speaker-Verification
Official release of pretrained models and scripts for 'Golden Gemini Is All You Need: Finding the Sweet Spots for Speaker Verification' accepted by IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP), 2024.

arXiv Link: https://arxiv.org/abs/2312.03620

(Free access) IEEE link: TO ADD.

# Note:
1. Special thanks to Dr. Liu Bei for sharing the code related to DF-ResNet (https://ieeexplore.ieee.org/document/10119228).
2. The purpose of this repository is to share pretrained models in the paper. Gemini DF-ResNet is soon available on Wespeaker (https://github.com/wenet-e2e/wespeaker/tree/master/examples/voxceleb/v2). Thanks to the Wespeaker community for their assistance, with special recognition to Dr. Wang Shuai.
3. [New] We also release a large-margin finetuned pretrained model.

# Pretrained Models

|  Model               | Param | Large Margin Fine-Tuning | Vox1-O EER | Vox1-O MinDCF | Vox1-E EER | Vox1-E MinDCF | Vox1-H EER | Vox1-H MinDCF | Pretained Model Folder                                                                                |
|----------------------|-------|--------------------------|------------|---------------|------------|---------------|------------|---------------|-------------------------------------------------------------------------------------------------------|
|  Gemini DF-ResNet60 [[Google Drive]](https://drive.google.com/file/d/1zfck1eEOFCxGonRRxUzsLKeruwv4f-kU/view?usp=sharing)  | 4.05  |  X                       | 0.941      | 0.089         | 1.051      | 0.116         | 1.799      | 0.166         | 0611-Gemini_df_resnet56-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-AdamW-epoch165     |
|  Gemini DF-ResNet114 [[Google Drive]](https://drive.google.com/file/d/1hruxkctjIzzUkooXikExb3if8wurR6pv/view?usp=sharing) | 6.53  |  X                       | 0.686      | 0.067         | 0.863      | 0.097         | 1.490      | 0.144         | 0615-Gemini_df_resnet110-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-AdamW-epoch165    |
|  Gemini DF-ResNet183 [[Google Drive]](https://drive.google.com/file/d/1Bb1VaD8ZoUREoRoQ73oiCXjIJ21SuKLS/view?usp=drive_link) | 9.20  |  X                       | 0.596      | 0.065         | 0.806      | 0.090         | 1.440      | 0.137         | 0621-Gemini_df_resnet179-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-AdamW-epoch165    |
|  [New] Gemini DF-ResNet183 [[Google Drive]](https://drive.google.com/file/d/1rEb5UpeOvirCt9mhIW54BRAd-6EF3n_c/view?usp=drive_link) | 9.20  | ✔                        | 0.569      | 0.045         | 0.768      | 0.078         | 1.342      | 0.126         | 0621-Gemini_df_resnet179-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-AdamW-epoch165-LM |

*: The layer count between the names of the pretrained model folder and the model itself differs by 4, as mentioned in footnote 4 of the paper, where the distinction lies in whether to include the 4 separate downsampling layers in the layer count.  **The models are identical, only differing in nomenclature.** During experimentation, we did not include the separate downsampling layers in the layer count; however, through discussion during paper writing, we decided to include. **Therefore, Gemini DF-ResNet60/114/183 are the official name.**

# Folder Structure:

Take 0611-Gemini_df_resnet56-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-AdamW-epoch165 as an example:

```
├── models/
│ ├── model_165.pt                                            # The model checkpoint of 165 epoch. This is the model for testing.
├── scores/
│ ├── vox1_asnorm300_result                                   # testing results with asnorm
│ ├── vox1_snorm300_result                                    # testing results with snorm
│ ├── vox1_cos_result                                         # testing results simply by cosine similarity 
│ ├── vox2_dev_asnorm300_vox1_O_cleaned.kaldi.det.png         # visualization
│ ├── vox2_dev_asnorm300_vox1_H_cleaned.kaldi.det.png
│ ├── vox2_dev_asnorm300_vox1_E_cleaned.kaldi.det.png
│ ├── vox2_dev_asnorm300_vox1_O_cleaned.kaldi.score           # scores of all the trials
│ ├── vox2_dev_asnorm300_vox1_H_cleaned.kaldi.score
│ └── vox2_dev_asnorm300_vox1_E_cleaned.kaldi.score
└── config.yaml                                               # The config file to train the model in wespeaker platform (https://github.com/wenet-e2e/wespeaker/tree/master/examples/voxceleb/v2/conf)
└── train.log                                                 # The training log automatically generated by the Wespeaker toolkit. 
```



# Usage:

**[Important]**
**The Gemini DF-ResNet is soon to be available in Wespeaker (https://github.com/wenet-e2e/wespeaker/tree/master/examples/voxceleb/v2). We encourage using the version provided by Wespeaker for better compatibility.** 

Alternatively, you can follow the steps below to reproduce the provided checkpoint:
  1. Set up Wespeaker Toolkit (https://github.com/wenet-e2e/wespeaker).
  2. Copy the model file, Gemini_df_resnet.py, from this repository to wespeaker/wespeaker/models/
  3. Modify wespeaker/wespeaker/models/speaker_model.py by adding
       ```
       import wespeaker.models.Gemini_df_resnet as Gemini_df_resnet
       ```
       and
       ```
       elif model_name.startswith("Gemini_df_resnet"):
         return getattr(Gemini_df_resnet, model_name)
       ```
  4. Create a config file following the config.yaml file in the pre-trained model folder and place it in /wespeaker/examples/voxceleb/v2/conf/
     [Note]: Warm-up is utilized by default as indicated below, although it is not explicitly specified in the configuration file.
     ```
       warm_from_zero: False
       warm_up_epoch: 6
     ```
  6. In wespeaker/examples/voxceleb/v2/run.sh, modify 'config' to point to the new config file.
  And then you can start training and reproduce.

# Cite
**Golden Gemini (this work):**
```  
  @article{liu2023golden,
    title={Golden Gemini is All You Need: Finding the Sweet Spots for Speaker Verification},
    author={Liu, Tianchi and Lee, Kong Aik and Wang, Qiongqiong and Li, Haizhou},
    journal={arXiv preprint arXiv:2312.03620},
    year={2023}
  }
```

**Related Work:**

DF-ResNet
```  
@ARTICLE{10119228,
  author={Liu, Bei and Chen, Zhengyang and Qian, Yanmin},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Depth-First Neural Architecture With Attentive Feature Fusion for Efficient Speaker Verification}, 
  year={2023},
  volume={31},
  pages={1825-1838}
}
```

wespeaker toolkit
```
@article{wang4748855advancing,
  title={Advancing Speaker Embedding Learning: Wespeaker Toolkit for Research and Production},
  author={Wang, Shuai and Chen, Zhengyang and Han, Bing and Wang, Hongji and Liang, Chengdong and Zhang, Binbin and Xiang, Xu and Ding, Wen and Rohdin, Johan and Silnova, Anna and others},
  journal={Available at SSRN 4748855}
}
```

